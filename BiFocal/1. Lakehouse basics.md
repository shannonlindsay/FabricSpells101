# Lakehouse Basics

## Create a Workspace

<!--Navigate to Fabric Home through Power BI - https://app.powerbi.com

Login with your allocated user ID (Fabxxx@fabricconf.onmicrosoft.com). If required, change the password, and select "Later" to set up multi-factor authentication.

Select the "Power BI" experience. -->

Select Workspaces from the left rail

![alt text](assets/01_Lakehouse%20basics__workspaces.png)

Select New workspace - Use the name "Fabric Tutorial xxx" where xxx is your user number (as in Fabxxx@fabricconf.onmicrosoft.com).

Open the advanced tab and make sure that the License mode is Trial, Premium, or Fabric. If not, set it to one of these.

![](assets/20240318_100437_image.png)

Click the "Apply" button to create the workspace.

> **Taskflows**
>
> When you first enter the workspace, you may see a section for Taskflows. Taskflows can be a great way to follow certain common data patterns. If this is too distracting, you can collapse the Taskflows pane by selecting the caret icon in the divider pane to collaps and later to show again.
>
> ![](assets/empty-taskflows.jpg)

## Create a Lakehouse

In your new workspace, select the "+ New item" button in the ribbon.

Scroll down to the "Store data" section and select the Lakehouse tile. Or, you can type in *Lakehouse* within the filter box.

Give the Lakehouse a name - use "Lakehouse_Fabxxx" where xxx is your user number. Note that the name can NOT include spaces. Do **NOT** check the "Lakehouse schemas" checkbox. Click the "Create" button. Once the lakehouse is created, you will be taken directly to it.

Note the two containers: Files and Tables. Both folders are empty.

![](assets/20241125_100352_image.png)

## Add File content

Download all of the CSVs located [here](https://github.com/jasonhimmelstein/FabricForPowerBI/tree/main/Recent%20Thermostat%20Data) to your local device. You can use [GitHub Desktop](https://desktop.github.com/) to clone the repo, download the files individually, or download the .zip file that contains all of the files in the folder. We will be using these files throughout the exercises.

From your Lakehouse, click the ellipsis to the right of the Files container, and select "New subfolder". Name it "Recent thermostat files", and click "Create".

Using the ellipsis to the right of your new subfolder, select "Upload". and upload the CSV for August that you downloaded above. After seeing the green check mark next to the file size you can close the upload files window by clicking the "X" in the top right corner.

![](assets/20240318_102359_image.png)

Click on the "Recent themostat files" sub-folder, then click on the "2023 - August.csv" file to view the content. 

![alt text](assets/01_Lakehouse%20basics__explore_data.png)

Click on "Recent Thermostat files" in the Explorer pane. Hover over the folder and select the ellipsis that appears. Select Properties.

![](assets/20240905_131350_image.png)

Note the URL that appears. This could be used with the Azure Data Lake Storage Gen2 (ADLS Gen2) connector in Power BI Desktop to build a report against this data, but we will use another mechanism. It can also be used with any tool that works with ADLS Gen 2.

Close the Properties pane.

## Move CSV to Delta tables

Hover over the CSV file, select the ellipsis, and click on "Load to Tables".

![](assets/20240318_102555_image.png)

Select "New table" and name your table "thermostat_readings". Take the defaults for Column Header & Separator. Click the "Load" button.

![](assets/20240318_102907_image.png)

Loading will take a moment, and will load the data from the CSV into the Tables endpoint where it will be stored in delta-parquet files to allow for transactional access and the SQL endpoint.

Open the Tables node. If it is empty, select refresh from the ribbon on the top of the page. Note the new table there with the small triangle icon. That icon indicates that the table is in Delta format.

Click on the new table and observe the preview (1000 rows). It will take a moment to initialize the Spark engine the first time, as this view is using a SQL query, not simply viewing the contents of a file.

![](assets/20241125_101633_image.png)

## Add table to the default semantic model

In the upper right hand corner of the table view, there is a dropdown button labeled "Lakehouse". This means that we are in the Lakehouse view of the table. We need to switch to the SQL endpoint view, so select it, and select "SQL analytics endpoint".

![](assets/20241125_101805_image.png)

You will then be taken to the SQL analytics endpoint view. Click on the "Reporting" tab at the top of the ribbon, then click on the "Manage default semantic model" button in the ribbon. Navigate the schema from dbo, to Tables, and then select the "thermostat_readings" table for inclusion in the default model, and click "Confirm".

![](assets/20241125_102101_image.png)

> **Default Semantic Model vs New Semantic Model**
>
> There are things to consider with using the default semantic model that comes with a Lakehouse. Doing this will make sure that the tables are always updated. This helps to allow Power BI reports, in Direct Lake mode, reflect the most recent data.
>
> Creating a new semantic model will give you the option to control whether these automatic updates happen or not. In a production roll out, chances are that you will want to control when you point to the most recent data if you are doing a data load. Consider that the fact table may be updated first and then the dimensions. If you are leveraging automatic updates, this may lead to missing data within the report or confusing results.

## Create Power BI report from the table (PBI Desktop)

Start Power BI Desktop. Log in with your Fabxxx@fabricconf.onmicrosoft.com ID. Create a new blank report.

![alt text](assets/Blank%20report.png)

Select the Get data button from the ribbon. Select the "Microsoft Fabric" blade. Choose "Lakehouses" and then click the "Connect" button.

![](assets/20240318_103936_image.png)

Your "Lakehouse_Fabxxx" lakehouse will appear in the list. Select it, and click "Connect" (not "Connect to SQL endpoint"). Notice that you did not need to authenticate, as your credentials were passed in automatically.

Select "Data" from the right side rail to expand the data sources.

![alt text](assets/Desktop%20data%20sources.png)

Notice also that Power Query was not loaded, and the table created above appears automatically

Drag Outdoor Temperature and Time onto a line chart on the canvas. It may take a moment for the visual to update. Notice that the sum of temperature is used, which we can change to average (as an implicit measure). We would prefer to use an explicit (calculated) measure as a best practice, but we haven't created any yet. We are connected to a remote semantic model as noted in the status bar at the bottom. This is a [Direct Lake](https://learn.microsoft.com/fabric/get-started/direct-lake-overview) connection. Also note the fact that there is no date hierarchy.

![](assets/01_Lakehouse%20basics__create_report.png)

Close Power BI Desktop without saving as we will not be using Power BI Desktop further. 

## Create a View for time intelligence

Open the "Fabric Tutorial xxx" workspace in the service, and then open the "Lakehouse_Fabxxx" Lakehouse.

From the upper right hand corner, change the "Lakehouse" dropdown to "SQL analytics endpoint".

(Alternatively, you could select the lakehouse's SQL analytics endpoint from the workspace)

Select the "New SQL query" button in the ribbon or from the canvas. 

Expand the "thermostat_readings" table to see all of the available columns. 

Add lines to extract year, month and day into separate columns. Also, cast the Time column to Time instead of DateTime. ***Note - if you are copying and pasting the code below, be sure to change the lakehouse name to your correct one***. When complete, the query should appear as follows:

```Sql
select [Date],
    Cast([Time] as Time) as [Time],
    [Outdoor_Temp],
    [Cool_Stage_1],
    [Cool_Stage_2],
    [Heat_Stage_1],
    [Heat_Stage_2],
    YEAR([Date]) as [Year],
    MONTH([Date]) as MonthNumber,
    DATENAME(Month,[Date]) as Month,
    DAY([Date]) as [Day]
from [Lakehouse_Fabxxx].[dbo].[thermostat_readings] as [$Table]
```

Run the query to ensure that it works. When satisfied, select the query text and click the "Save as view" button (next to the "Run" button). Name your view "vwThermostatReadings"

![](assets/20241125_104646_image.png)

> **Best Practice: Star Schema**
>
> The above is a simple example of how we can create items and build out reports. In a production scenario, understand that Power BI reports work best with what is called a star schema table layout. A star schema pattern is an industry data warehousing concept and not limited to just Power BI.
>
> A way to look at it would be if the above were split out where date attributes were broken out into it's own dimension table, and the temperature readings would bein a fact table. Related by the date itself.
>
> This allows you to quickly slice and dice within Power BI and improves model sizes which contribute to faster query and refresh times.
>
> Learn more: [Understanding star schema and the importance for Power BI](https://learn.microsoft.com/power-bi/guidance/star-schema)

## Edit the Semantic Model in the service

Click the "Model layouts" blade at the bottom of the explorer pane or the toolbar, and then the "Reporting" tab at the top. Click the "Automatically update semantic model" button to add the newly created view to the semantic model.

![](assets/20241125_105730_image.png)

We want to create an explicit measure for average temperature. Click on the ellipsis for "vwThermostatReadings" in the model layouts window, and select "New measure".

![](assets/1.Lakehouse%20basics__add_measure_to_view.png)

Create the following calculated measure:

```PlainText
Average Temperature = AVERAGE(vwThermostatReadings[Outdoor_Temp])
```

Save the measure, and scroll down on the "vwThermostatReadings" table. You should see the new measure at the bottom.

![alt text](assets/01_Lakehouse%20basics__measure_in_model.png)

Click the ellipsis on the other table ("thermostat_readings"), and select "Hide in report view". 

Select "Month" from the vwThermostatReadings table. In the properties pane on the right, open the advanced section, and choose MonthNumber in the "Sort by column" dropdown. This will allow the month name to be sorted chronologically.

![](assets/20241125_111407_image.png)

Select "Year" from the "vwThermostatReadings" table, then select its ellipsis, and select "Create hierarchy". Name the hierarchy "Date hierarchy". Add Month and Day to the hierarchy, then select "Apply Level Changes".

![](assets/20241125_112301_image.png)

## Create Power BI report in the service

Click the "Reporting" tab, and then the "New report" button. A new Power BI report will open. 

Minimize the Filters pane.

Add a Line and Clustered column chart visual to the canvas.

![alt text](assets/01_Lakehouse%20basics__line_and_clustered.png)

Open the vwThermostatReadings table in the Data pane.

Add Cool_Stage_1, Cool_Stage_2, Heat_Stage_1, Heat_Stage_2 to the Column y-axis

Add Average Temperature to the Line y-axis

Add Date Hierarchy to the X axis. 


![](assets/20241125_112909_image.png)

Save the report, and name it "Thermostat report 1". Ensure that you save it to the "Fabric Tutorial xxx" workspace.

In this lab, you have ingested data, transformed it, modified the default model and bult a report, all without having to use Power BI Desktop.

You can now proceed to [Data Transformation with Notebooks and Spark](./2.%20Data%20Transformation%20with%20Notebooks%20and%20Spark.md) to continue the labs.